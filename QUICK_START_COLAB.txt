================================================================================
ðŸš€ QUICK START - TRAIN ON GOOGLE COLAB (100 COMPUTE UNITS)
================================================================================

ðŸŽ¯ RECOMMENDATION: 03_train_colab_highmem.py + GPU T4
   â†’ Accuracy: 90-95%
   â†’ Time: 15-20 minutes
   â†’ Cost: ~50-80 units (cÃ²n dÆ° 20-50 units!)

================================================================================
ðŸ“‹ STEP-BY-STEP GUIDE
================================================================================

1ï¸âƒ£  SETUP COLAB RUNTIME
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   a) Má»Ÿ Google Colab: https://colab.research.google.com
   b) Runtime â†’ Change runtime type
   c) Chá»n:
      â€¢ Python 3
      â€¢ Hardware accelerator: GPU â­
      â€¢ Runtime shape: High-RAM â­
   d) Save â†’ Connect

   Verify GPU:
   !nvidia-smi
   
   Expected output: Tesla T4, 15360 MiB

2ï¸âƒ£  UPLOAD FILES TO COLAB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Option A: Via Google Drive (Recommended for large files)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   from google.colab import drive
   drive.mount('/content/drive')
   
   # Copy data to Colab storage (faster than Drive)
   !mkdir -p /content/merged_batches
   !cp /content/drive/MyDrive/IOT_Project/merged_batches/*.csv /content/merged_batches/
   
   # Copy script
   !cp /content/drive/MyDrive/IOT_Project/03_train_colab_highmem.py /content/
   
   Option B: Direct Upload (Slower but simpler)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   from google.colab import files
   
   # Upload batches (this will take time for ~10GB files)
   uploaded = files.upload()  # Select: batch_01.csv, batch_02.csv, batch_04.csv, batch_05.csv
   
   # Create folder and move
   !mkdir -p merged_batches
   !mv batch_*.csv merged_batches/
   
   # Upload script
   uploaded = files.upload()  # Select: 03_train_colab_highmem.py

3ï¸âƒ£  INSTALL DEPENDENCIES
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   !pip install -q xgboost scikit-learn imbalanced-learn pandas numpy joblib psutil

4ï¸âƒ£  RUN TRAINING
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   !python 03_train_colab_highmem.py
   
   Expected output:
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   TRAIN TWO-STAGE MODEL - COLAB PRO+ HIGH-RAM
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   XGBoost version: 2.x.x
   ðŸš€ GPU detected: Tesla T4, 15360 MiB
   
   ... (training progress) ...
   
   ðŸ“Š Overall Accuracy: 0.92XX
   âœ… TRAINING COMPLETED!
   
   â±ï¸  Total time: 15-20 minutes

5ï¸âƒ£  DOWNLOAD TRAINED MODELS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   # Zip models
   !zip -r models_full.zip models_full/
   
   # Download
   from google.colab import files
   files.download('models_full.zip')
   
   Models include:
   â”œâ”€ stage1_TIMESTAMP.pkl        (Binary: Attack vs Normal)
   â”œâ”€ stage2_TIMESTAMP.pkl        (Multi-class: Attack types)
   â”œâ”€ encoders_TIMESTAMP.pkl      (Feature encoders)
   â”œâ”€ mapping_TIMESTAMP.pkl       (Attack type mapping)
   â””â”€ features_TIMESTAMP.pkl      (Feature list)

================================================================================
ðŸŽ¯ ALTERNATIVE: BUDGET VERSION (30-50 units)
================================================================================

If you want to save compute units:

1ï¸âƒ£  Runtime: Standard + GPU T4 (NOT High-RAM)
2ï¸âƒ£  File: 03_train_colab_pro.py
3ï¸âƒ£  Trade-off:
   â€¢ Accuracy: 85-90% (instead of 90-95%)
   â€¢ Data: 20M records (instead of 30M)
   â€¢ Time: 10-15 min
   â€¢ Cost: ~30-50 units

================================================================================
âš ï¸  TROUBLESHOOTING
================================================================================

Issue: "CUDA out of memory"
Fix: Restart runtime â†’ Disconnect â†’ Reconnect

Issue: "RAM/Disk quota exceeded"
Fix: Use 03_train_colab_pro.py (uses less RAM)

Issue: "No GPU detected"
Fix: Runtime â†’ Change runtime type â†’ GPU â†’ Save

Issue: "Training very slow (>1 hour)"
Fix: Check GPU with !nvidia-smi
     If no GPU or K80 â†’ Disconnect â†’ Reconnect

Issue: Script crashes
Fix: Check file paths:
     !ls -lh merged_batches/
     Should show: batch_01.csv, batch_02.csv, batch_04.csv, batch_05.csv

================================================================================
ðŸ“Š EXPECTED RESULTS
================================================================================

With 03_train_colab_highmem.py + GPU T4:

Stage 1 (Attack vs Normal):
   Accuracy:  0.998+
   Precision: 0.998+
   Recall:    0.999+
   F1-Score:  0.999+
   ROC-AUC:   0.999+

Stage 2 (Attack Types):
   Accuracy:  0.92+
   Precision: 0.91+ (weighted)
   Recall:    0.92+ (weighted)
   F1-Score:  0.91+ (weighted)

Overall Pipeline:
   Accuracy:  0.92-0.95 (92-95%)

================================================================================
ðŸ’° COMPUTE UNITS BREAKDOWN
================================================================================

Total budget: 100 units

Training (High-RAM + GPU T4):
   Runtime: 15-20 minutes
   Cost: ~50-80 units
   
Remaining: 20-50 units for:
   â€¢ Re-training with different hyperparameters
   â€¢ Testing/inference
   â€¢ Model evaluation
   â€¢ Experiments

================================================================================
ðŸ“ž NEED HELP?
================================================================================

1. Check GPU: !nvidia-smi
2. Check RAM: Script prints RAM usage automatically
3. Check files: !ls -lh merged_batches/
4. XGBoost version: !python -c "import xgboost; print(xgboost.__version__)"
5. Full log saved in terminal output

Good luck! ðŸš€

================================================================================

