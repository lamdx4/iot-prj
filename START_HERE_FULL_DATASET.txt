â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    âœ… PROJECT SETUP HOÃ€N THÃ€NH! âœ…
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Äá» tÃ i: PhÃ¡t hiá»‡n táº¥n cÃ´ng IoT báº±ng Machine Learning
Approach: Two-Stage Hierarchical Classification

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ STRUCTURE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

src/
â”œâ”€â”€ dataset_5percent/                      â† 5% Dataset (Baseline)
â”‚   â””â”€â”€ 04_hierarchical_two_stage_classification.py
â”‚
â””â”€â”€ dataset_full/                          â† Full Dataset (Production) â­
    â”œâ”€â”€ scripts/
    â”‚   â”œâ”€â”€ 01_merge_files.py             â† Gá»™p 10 files â†’ 1 batch
    â”‚   â”œâ”€â”€ 02_analyze_batches.py         â† Statistics â†’ JSON
    â”‚   â”œâ”€â”€ 03_train_hierarchical.py      â† Train models
    â”‚   â””â”€â”€ 04_test_model.py              â† Test models
    â”‚
    â”œâ”€â”€ stats/                             â† Generated stats
    â”œâ”€â”€ RUN_PIPELINE.sh                    â† Auto run all â­
    â””â”€â”€ README.md

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¯ 2 CÃCH TRAIN
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ CÃCH 1: Dataset 5% (Quick & Baseline)                                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                           â•‘
â•‘   cd src/dataset_5percent                                                 â•‘
â•‘   python 04_hierarchical_two_stage_classification.py                      â•‘
â•‘                                                                           â•‘
â•‘   â±ï¸  Time: ~5 phÃºt                                                       â•‘
â•‘   ğŸ’¾ Memory: ~2GB                                                          â•‘
â•‘   ğŸ“Š Accuracy: 99.6%                                                       â•‘
â•‘   âš ï¸  Limitation: Only 4 Normal samples                                   â•‘
â•‘                                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ CÃCH 2: Full Dataset (Production) â­ RECOMMENDED!                        â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                           â•‘
â•‘   cd src/dataset_full                                                     â•‘
â•‘   ./RUN_PIPELINE.sh                                                       â•‘
â•‘                                                                           â•‘
â•‘   Pipeline tá»± Ä‘á»™ng:                                                       â•‘
â•‘   1. Gá»™p 74 files â†’ 8 batches (~10 phÃºt)                                 â•‘
â•‘   2. PhÃ¢n tÃ­ch â†’ JSON stats (~5 phÃºt)                                    â•‘
â•‘   3. Train models (~15 phÃºt)                                              â•‘
â•‘   4. Test models (~3 phÃºt)                                                â•‘
â•‘                                                                           â•‘
â•‘   â±ï¸  Total: ~30 phÃºt                                                     â•‘
â•‘   ğŸ’¾ Memory: ~8-16GB                                                       â•‘
â•‘   ğŸ“Š Accuracy: 98-99%                                                      â•‘
â•‘   âœ… Advantage: 10K-20K Normal samples â†’ Reliable!                        â•‘
â•‘                                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ” FULL DATASET PIPELINE CHI TIáº¾T
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

STEP 1: Gá»™p 10 files thÃ nh 1 batch
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â€¢ Input: 74 files tá»« Data/Dataset/Entire Dataset/
  â€¢ Output: 8 batch files
    - batch_01.csv (files 1-10, ~2GB)
    - batch_02.csv (files 11-20, ~2GB)
    - ...
    - batch_08.csv (files 71-74, ~0.8GB)
  
  â€¢ IMPORTANT:
    âœ“ Sort Ä‘Ãºng thá»© tá»± (1,2,3... not 1,10,11...)
    âœ“ Sort theo stime (flow data)
    âœ“ LÆ°u vÃ o Data/Dataset/merged_batches/

STEP 2: PhÃ¢n tÃ­ch batches â†’ JSON
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â€¢ Input: 8 batch files
  â€¢ Output: src/dataset_full/stats/batch_statistics.json
  
  â€¢ Statistics per batch:
    âœ“ Number of records
    âœ“ Class distribution (Normal, DDoS, DoS, Recon)
    âœ“ Attack vs Normal ratio
    âœ“ Missing values
    âœ“ Protocol distribution
    âœ“ Time range (stime, ltime)
  
  â€¢ Recommendations:
    âœ“ Which batches to use
    âœ“ Imbalance handling strategy
    âœ“ SMOTE parameters

STEP 3: Train Models
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â€¢ Äá»c JSON statistics
  â€¢ Chá»n best batches (priority: batches vá»›i nhiá»u Normal)
  â€¢ Load & merge selected batches
  
  â€¢ STAGE 1: Binary Classification (Attack vs Normal)
    âœ“ SMOTE for Normal samples
    âœ“ XGBoost vá»›i scale_pos_weight
    âœ“ Save stage1_binary_*.pkl
  
  â€¢ STAGE 2: Multi-class (DDoS, DoS, Reconnaissance)
    âœ“ Only attack samples (no Normal)
    âœ“ SMOTE for minority (Reconnaissance)
    âœ“ Save stage2_multiclass_*.pkl
  
  â€¢ Test on 5% dataset (test set)
  â€¢ Save metrics JSON

STEP 4: Test Models
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â€¢ Load trained models
  â€¢ Predict on test set
  â€¢ Detailed evaluation:
    âœ“ Per-class metrics
    âœ“ Confusion matrix
    âœ“ Error analysis
    âœ“ Sample predictions
  
  â€¢ Save test_results_*.json

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š EXPECTED RESULTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Full Dataset (sau khi merge):
  âœ“ Total records: 40-50 million
  âœ“ Normal samples: 10,000-20,000 (vs 4 trong 5%)
  âœ“ Attack samples: 40-50 million
  âœ“ Imbalance ratio: 2,000-5,000:1 (better than 9,782:1 cá»§a 5%)

Performance:
  âœ“ Stage 1 Accuracy: 99.5-99.9%
  âœ“ Stage 2 Accuracy: 98-99%
  âœ“ Overall Accuracy: 98-99.5%
  âœ“ Normal detection: RELIABLE (vs unreliable vá»›i 5%)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“‚ OUTPUT FILES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Data/Dataset/merged_batches/
â”œâ”€â”€ batch_01.csv  (~2GB)
â”œâ”€â”€ batch_02.csv  (~2GB)
...
â””â”€â”€ batch_08.csv  (~0.8GB)

src/dataset_full/stats/
â”œâ”€â”€ batch_statistics.json  â† Chi tiáº¿t tá»«ng batch
â””â”€â”€ batch_summary.txt       â† Human-readable summary

models/full_dataset/
â”œâ”€â”€ stage1_binary_TIMESTAMP.pkl          â† Stage 1 model
â”œâ”€â”€ stage2_multiclass_TIMESTAMP.pkl      â† Stage 2 model
â”œâ”€â”€ label_encoder_TIMESTAMP.pkl          â† Protocol encoder
â”œâ”€â”€ attack_mapping_TIMESTAMP.pkl         â† Attack type mapping
â”œâ”€â”€ feature_columns_TIMESTAMP.pkl        â† Feature names
â”œâ”€â”€ metrics_TIMESTAMP.json               â† Training metrics
â””â”€â”€ test_results_TIMESTAMP.json          â† Test results

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ’¡ TIPS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Memory Management:
  â€¢ 8GB RAM:  Sá»­a NUM_BATCHES_TO_USE = 2 trong 03_train_hierarchical.py
  â€¢ 16GB RAM: DÃ¹ng default (5 batches)
  â€¢ 32GB+ RAM: DÃ¹ng all 8 batches

Speed Optimization:
  â€¢ Giáº£m n_estimators tá»« 200 â†’ 100
  â€¢ Giáº£m max_depth tá»« 6 â†’ 4

Batch Selection:
  â€¢ Scripts tá»± Ä‘á»™ng chá»n batches vá»›i nhiá»u Normal nháº¥t
  â€¢ Check stats/batch_summary.txt Ä‘á»ƒ xem distribution

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ CHO Äá»€ TÃ€I
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Recommended Flow:

1. Train 5% dataset (baseline)
   â†’ Quick results
   â†’ Understand pipeline

2. Train Full dataset (production)
   â†’ Better Normal detection
   â†’ More reliable evaluation

3. So sÃ¡nh káº¿t quáº£:
   â†’ Show improvement
   â†’ Highlight Normal samples
   â†’ Explain why Full better

4. BÃ¡o cÃ¡o:
   â†’ EDA (notebooks/01_eda_dataset_analysis.ipynb)
   â†’ Methodology (Two-stage approach)
   â†’ Results (5% vs Full comparison)
   â†’ Conclusion (Production-ready)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸš€ Báº®T Äáº¦U NGAY!
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Quick Test (5%):
    cd src/dataset_5percent
    python 04_hierarchical_two_stage_classification.py

Production (Full): â­
    cd src/dataset_full
    ./RUN_PIPELINE.sh

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“š DOCUMENTATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  â€¢ PROJECT_STRUCTURE.md       â† Overall structure
  â€¢ src/README.md               â† Source code guide
  â€¢ src/dataset_full/README.md  â† Full pipeline detailed guide
  â€¢ QUICK_START_FULL.md         â† Quick reference

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Táº¤T Cáº¢ ÄÃƒ Sáº´N SÃ€NG!

Cháº¡y: cd src/dataset_full && ./RUN_PIPELINE.sh

Good luck! ğŸ€

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


